FROM rwthika/ros2-torch:jazzy-ros-base-torch2.5.0

MAINTAINER Jesse Morris "jesse.morris@sydney.edu.au"


# To avoid tzdata asking for geographic location...
ENV DEBIAN_FRONTEND=noninteractive

#Install build dependencies
RUN apt-get update && apt-get upgrade -y --allow-downgrades --no-install-recommends apt-utils
RUN apt-get update && apt-get install -y --allow-downgrades git cmake build-essential pkg-config
# Install xvfb to provide a display to container for GUI realted testing.
RUN apt-get update && apt-get install -y --allow-downgrades xvfb

# In the arm64 version of the base image we do not have the nvidia-cuda-development toolkit
# as explained https://github.com/ika-rwth-aachen/docker-ros-ml-images/issues/16
# this contains nvcc (ie we dont have it)
# we need nvcc to build opencv with cuda
# add extra nvidia container apt repository (otherwise we cannot find nvidia-cuda-toolkit)
RUN curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \
  && curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
    sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list


#NOTE: both nvidia-cuda-toolkit and cuda-toolkit are needed (particularly for header files)
RUN apt-get update \
    && apt-get install -y \
    python3-pip \
    openssh-client \
    software-properties-common \
    nano \
    vim \
    clang-format \
    nvidia-cuda-toolkit \
    cuda-toolkit \
    libnvinfer-dev \
    libnvonnxparsers-dev \
    tensorrt-dev \
    && pip3 install black pre-commit \
    && rm -rf /var/lib/apt/lists/*



# # ROS installs
RUN apt-get update && apt-get install -y \
      ros-jazzy-ros2cli-common-extensions \
      ros-jazzy-cv-bridge \
      ros-jazzy-vision-opencv \
      ros-jazzy-pcl-ros \
      ros-jazzy-rmw-fastrtps-cpp \
      ros-jazzy-rmw-zenoh-cpp \
      ros-jazzy-image-transport \
      libpcl-conversions-dev

# other deps
# RUN apt-get install libpng++-dev
# is libpng-dev different from libpng++? I think not available as a apt for aarm64
# RUN apt-get install libpng-dev

RUN python3 -m pip install pylatex evo setuptools pre-commit scipy argcomplete black pre-commit

# Install glog, gflags
RUN apt-get update && apt-get install -y libgflags2.2 libgflags-dev libgoogle-glog-dev

# Install xvfb to provide a display to container for GUI realted testing.
# vtk is needed for OpenCV to build its viz module (from contrib!)
RUN apt-get update && apt-get install -y xvfb python3-dev python3-setuptools libvtk9-dev

RUN pip3 install setuptools pre-commit scipy matplotlib argcomplete

# install CSparse
RUN DEBIAN_FRONTEND=noninteractive apt install -y libsuitesparse-dev

# Parallelism C++ for CPU
RUN apt-get update && apt-get install -y libboost-all-dev libtbb-dev

WORKDIR /root/



# Install OpenCV for Ubuntu
RUN apt-get update && apt-get install -y \
      unzip \
      libjpeg-dev libpng-dev libpng++-dev libtiff-dev libgtk2.0-dev \
      libatlas-base-dev gfortran


RUN git clone https://github.com/opencv/opencv.git
RUN cd opencv && \
      git checkout tags/4.10.0 && \
      mkdir build

RUN git clone https://github.com/opencv/opencv_contrib.git
RUN cd opencv_contrib && \
      git checkout tags/4.10.0

# on aarch64 there is no binary for nlohmann-json3
RUN git clone https://github.com/nlohmann/json.git
RUN cd json && mkdir build && \
      cd build && \
      cmake .. && make -j$(nproc) install

# OpenCV looks for the cuDNN version in cudnn_version.h, but it's been renamed to cudnn_version_v8.h
RUN ln -sfnv /usr/include/$(uname -i)-linux-gnu/cudnn_version_v*.h /usr/include/$(uname -i)-linux-gnu/cudnn_version.h

# IMPORTANT: must specify CXX_17 version. Default is c++11 which will cause compilation issues
# On aarch64 we can enable NEON for CPU level optimisations
# It is vital we use gcc-11 as otheriwise we cannot compile the cuda level code (ie. CUDA 12.9)
RUN cd opencv/build && \
      cmake -DCMAKE_BUILD_TYPE=Release \
      -DCMAKE_INSTALL_PREFIX=/usr/local \
      -DCMAKE_CXX_STANDARD=17 \
      -D BUILD_opencv_python=OFF \
      -D BUILD_opencv_python2=OFF \
      -D BUILD_opencv_python3=ON \
      -D WITH_CUDA=ON \
      -D WITH_CUDNN=ON \
      -D INSTALL_CUDA_LIBS=OFF \
      -D CUDA_ARCH_PTX= \
      -D CUDA_ARCH_BIN=8.7 \
      -D CUDNN_INCLUDE_DIR=/usr/include/$(uname -i)-linux-gnu \
      -D OPENCV_DNN_CUDA=ON \
      -D ENABLE_FAST_MATH=ON \
      -D CUDA_FAST_MATH=ON \
      -D WITH_VTK=ON \
      -D WITH_CUFFT=ON \
      -D WITH_CUBLAS=ON \
      -D WITH_TBB=ON \
      -DENABLE_NEON=ON \
      -D BUILD_TESTS=OFF \
      -D BUILD_PERF_TESTS=OFF \
      -D BUILD_opencv_ts=OFF \
      -D BUILD_opencv_sfm=OFF \
      -D BUILD_JAVA=OFF \
      -DOPENCV_EXTRA_MODULES_PATH=/root/opencv_contrib/modules .. && \
      make -j$(nproc) install

RUN git clone https://github.com/MIT-SPARK/config_utilities.git
RUN cd config_utilities/config_utilities && mkdir build && \
      cd build && \
      cmake .. && make -j$(nproc) install



# Install GTSAM
RUN git clone https://github.com/borglab/gtsam.git
RUN cd gtsam && \
    git fetch && \
    git checkout tags/4.2.0 && \
    mkdir build && \
    cd build && \
    cmake -DCMAKE_INSTALL_PREFIX=/usr/local \
    -DGTSAM_USE_SYSTEM_EIGEN=ON \
    -DGTSAM_BUILD_TESTS=OFF -DGTSAM_BUILD_EXAMPLES_ALWAYS=OFF -DCMAKE_BUILD_TYPE=Release -DGTSAM_BUILD_UNSTABLE=ON -DGTSAM_POSE3_EXPMAP=ON -DGTSAM_ROT3_EXPMAP=ON -DGTSAM_TANGENT_PREINTEGRATION=OFF .. && \
    make -j$(nproc) install


# Install Open_GV
RUN git clone https://github.com/MIT-SPARK/opengv
RUN cd opengv && \
      mkdir build
RUN cd opengv/build && \
      cmake -DCMAKE_BUILD_TYPE=Release \
      -DCMAKE_INSTALL_PREFIX=/usr/local \
      .. && make -j$(nproc) install


RUN echo 'export RMW_IMPLEMENTATION=rmw_zenoh_cpp' >> ~/.bashrc

RUN mkdir -p /home/user/dev_ws/src/core
RUN mkdir -p /home/user/dev_ws/src/third_parties
RUN mkdir -p /home/user/upstream_ws/src

SHELL ["/bin/bash", "-c"]

RUN source /opt/ros/jazzy/setup.bash

WORKDIR /home/user/dev_ws
